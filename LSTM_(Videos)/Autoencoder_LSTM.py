# -*- coding: utf-8 -*-
"""Encoder+LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CznCfweWstU1nJAik_xUK4rvI2u-R9Am
"""
"""
Use stackAutoEncoders for dimensionality Reduction. Faster than PCA with better fit.
After reduction feed to LSTM
Train ACC - 87%
Test ACC- 86%
"""
!git clone https://github.com/pruvi007/ML_Datasets.git

import cv2
import os
import time
import sys
import argparse
import numpy as np 
import random

MAIN = "ML_Datasets/Videos/"
OP = "/media/diablo/Study Vids/VIDEOS_ENGINE/ML/python_ml_me/LSTM_project/Data"

# **********************************************************************************************
start = time.time()
print("Creating Dataset")

train_data = []
test_data = []
actions = ["boxing","handclapping","handwaving","jogging","walking"]

count = 0
level=0
for act in actions:
    folder = MAIN + act
    c = 0
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            c+=1
        
    test_percent = int(c/3)
    train_percent = c-test_percent

    flag = np.zeros(c+1)
    for x in range(test_percent):
        r = random.randint(0,c)
        flag[r]=1
    c=0
    
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            vid = folder+"/"+file
            s = vid.split("/")
            action_name = s[len(s)-2]
            if flag[c]==1:
                test_data.append([vid,action_name,level])
            else:
                train_data.append([vid,action_name,level])
            c+=1
    level+=1
print(len(train_data))
print(len(test_data))

# for i in range(len(train_data)):
#     print(train_data[i])
# print()
# for i in range(len(test_data)):
#     print(test_data[i])

np.random.shuffle(train_data)
np.random.shuffle(test_data)

train = []
test = []

for i in range(len(train_data)):
    train.append([train_data[i][0],train_data[i][2]])
for i in range(len(test_data)):
    test.append([test_data[i][0],test_data[i][2]])

# for i in range(len(train)):
#     print(train[i])
# print()
# for i in range(len(test)):
#     print(test[i])           

end = time.time()

print("Datsets Created. Done! Time: ",end - start)
# *************************************************************************************************

# ********************************************************************
# train the data 
import cv2
from keras.utils import to_categorical
from keras.models import Model,Sequential,load_model
from keras.layers import Dense,Conv3D,Dropout,Flatten,MaxPooling3D,Input
from keras.layers.recurrent import LSTM
import time 


img_x = []
img_y = []


start = time.time()
num_of_frames = 100
dim_x = 100
dim_y = 100
for i in  range(len(train)):
    vidObj = cv2.VideoCapture(train[i][0])
    label = train[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        # Saves the frames with frame-count 
        image = image/255
        img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(img_y))

img_x = np.array(img_x)
print(img_x.shape)
num = int(img_x.shape[0]/num_of_frames)
img_x = np.reshape(img_x,(num,num_of_frames,dim_x,dim_y))
print(img_x.shape)
img_y = np.array(img_y)
print(img_y.shape)

X = np.reshape(img_x,(img_x.shape[0],num_of_frames,dim_x*dim_y))

# img_y = np.reshape(img_y,(num_of_frames,img_x.shape[1],6))
X = np.reshape(X,(X.shape[0]*X.shape[1],X.shape[2]))
print(X.shape,img_y.shape)

# *******************************************
# Stacked AutEncoder to generate TRAIN
input_img = Input(shape=(X.shape[1],))
# encoder 1
enc1 = Dense(512,activation='relu')(input_img)
# output with softmax prob.
decode1 = Dense(X.shape[1],activation='sigmoid')(enc1)
encoder1 = Model(input_img,enc1)
encoder1.summary()
auto_enc1 = Model(input_img,decode1)
auto_enc1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
auto_enc1.fit(X,X,epochs=5,batch_size=128)

encoder1.save('Encoder1')
input1 = encoder1.predict(X)

input_img = Input(shape=(input1.shape[1],))
# encoder 2
enc1 = Dense(128,activation='relu')(input_img)
# output with softmax prob.
decode1 = Dense(input1.shape[1],activation='sigmoid')(enc1)
encoder2 = Model(input_img,enc1)
auto_enc2 = Model(input_img,decode1)
auto_enc2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
auto_enc2.fit(input1,input1,epochs=5,batch_size=128)

encoder2.save('Encoder2')
input2 = encoder2.predict(input1)

input2 = np.reshape(input2,(input2.shape[0]//num_of_frames,num_of_frames,input2.shape[1]))

print(input2.shape)
# this is the combined model with a softmax layer to fine tune the weights.
# **************************************************************


# *******************
# *************TEST CREATION***********
test_img_x = []
test_img_y = []

print("Creating test frames....")
for i in  range(len(test)):
    vidObj = cv2.VideoCapture(test[i][0])
    label = test[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    test_img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        image = image/255
        # Saves the frames with frame-count 
        test_img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break

test_img_x = np.array(test_img_x)
print(test_img_x.shape)
test_img_y = np.array(test_img_y)
num = int(test_img_x.shape[0]/num_of_frames)
test_img_x = np.reshape(test_img_x,(test_img_x.shape[0],test_img_x.shape[1]*test_img_x.shape[2]))
print(test_img_x.shape)
print(test_img_y.shape)

test_input1 = encoder1.predict(test_img_x)

test_input2 = encoder2.predict(test_input1)
test_input2 = np.reshape(test_input2,(test_input2.shape[0]//num_of_frames,num_of_frames,test_input2.shape[1]))
# ***********************************************************************************
# *****************************************************



final = Sequential()
# x = load_model('Encoder1')
final.add(LSTM(50,input_shape=(num_of_frames,input2.shape[2]),return_sequences=True,dropout=0.2))
final.add(Flatten())
final.add(Dense(6,activation='softmax'))

final.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])  
history = final.fit(input2, img_y, epochs=100,batch_size=128,validation_data=(test_input2,test_img_y))

import matplotlib.pyplot as plt
from matplotlib import style

plt.rcParams['figure.figsize'] = [10, 10]
style.use('fivethirtyeight')
# print(history.history)
loss = history.history['loss']
acc = history.history['acc']
val_acc = history.history['val_acc']
print(loss)
plt.plot(np.arange(100)+1,loss,linewidth='2')

plt.title('LOSS')
plt.xlabel('EPOCH')
plt.ylabel('LOSS')
plt.show()
print("\n\n")
print(acc)
plt.plot(np.arange(100)+1,acc,linewidth='2',label='TRAIN')
plt.plot(np.arange(100)+1,val_acc,linewidth='2',label='TEST')
plt.title('ACCURACY')
plt.xlabel('EPOCH')
plt.ylabel('ACCURACY')
plt.legend(loc='upper left')
plt.show()
