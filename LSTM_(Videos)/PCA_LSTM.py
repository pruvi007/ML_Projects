# -*- coding: utf-8 -*-
"""PCA_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nnlovgVl4UZDpjCPlhaXlG-eGt_s9WQX

Importing dataset from **GitHub** Directory
"""

!git clone https://github.com/pruvi007/ML_Datasets.git

"""From each directory getting videos for **Train and Test** purposes."""
"""
Reduce the number of features using PCA and then feed to LSTM. Very good results.
Train ACC- 96%
Test ACC- 81%
"""
import cv2
import os
import time
import sys
import argparse
import numpy as np 
import random

MAIN = "ML_Datasets/Videos/"
OP = "/media/diablo/Study Vids/VIDEOS_ENGINE/ML/python_ml_me/LSTM_project/Data"

# **********************************************************************************************
start = time.time()
print("Creating Dataset")

train_data = []
test_data = []
actions = ["boxing","handclapping","handwaving","jogging","walking"]

count = 0
level=0
for act in actions:
    folder = MAIN + act
    c = 0
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            c+=1
        
    test_percent = int(c/2)
    train_percent = c-test_percent

    flag = np.zeros(c+1)
    for x in range(test_percent):
        r = random.randint(0,c)
        flag[r]=1
    c=0
    
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            vid = folder+"/"+file
            s = vid.split("/")
            action_name = s[len(s)-2]
            if flag[c]==1:
                test_data.append([vid,action_name,level])
            else:
                train_data.append([vid,action_name,level])
            c+=1
    level+=1
print(len(train_data))
print(len(test_data))

# for i in range(len(train_data)):
#     print(train_data[i])
# print()
# for i in range(len(test_data)):
#     print(test_data[i])

np.random.shuffle(train_data)
np.random.shuffle(test_data)

train = []
test = []

for i in range(len(train_data)):
    train.append([train_data[i][0],train_data[i][2]])
for i in range(len(test_data)):
    test.append([test_data[i][0],test_data[i][2]])

# for i in range(len(train)):
#     print(train[i])
# print()
# for i in range(len(test)):
#     print(test[i])           

end = time.time()

print("Datsets Created. Done! Time: ",end - start)
# *************************************************************************************************

"""For each video** extracting frames** for both Train and Test sets"""

# ********************************************************************
# train the data 
import cv2
from keras.utils import to_categorical
from keras.models import Model,Sequential,load_model
from keras.layers import Dense,Conv3D,Dropout,Flatten,MaxPooling3D,Input
from keras.layers.recurrent import LSTM
from sklearn.decomposition import PCA

pca = PCA(n_components=100)
img_x = []
img_y = []

num_of_frames = 150
dim_x = 120
dim_y = 120
for i in  range(len(train)):
    vidObj = cv2.VideoCapture(train[i][0])
    label = train[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    img_y.append(Y_label)
    success = 1
    count=0
    while success: 
#         print(count)
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        f = cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR)
        
        # Saves the frames with frame-count 
        img_x.append(f)
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(img_y))
#print(len(img_x))
img_x = np.array(img_x)
print(img_x.shape)
num = int(img_x.shape[0]/num_of_frames)
img_x = np.reshape(img_x,(num,num_of_frames,dim_x,dim_y))
print(img_x.shape)
img_y = np.array(img_y)
print(img_y.shape)

# np.save('X.npy',img_x)
# np.save('Y.npy',img_y)

# img_x = np.load('X.npy')
img_x1= img_x[:img_x.shape[0],:]
img_x11=np.reshape(img_x1,(img_x.shape[0],num_of_frames,dim_x*dim_y))
img_x11.shape

"""Performing** PCA**,  transforming the feature space by extracting prominent features."""

from sklearn.decomposition import PCA
n_comp = 128
pca = PCA(n_components=n_comp)
finalimg_x=[]
#principalComponents = pca.fit_transform(img_x11)
for i in range(img_x11.shape[0]):
  principalComponents = pca.fit_transform(np.reshape(img_x11[i,:,:],(num_of_frames,dim_x*dim_y)))
  finalimg_x.append(principalComponents)

finalimg_x=np.array(finalimg_x)  
print(finalimg_x.shape)  
print(img_y.shape)

"""creating the  model for PCA ** LSTM**"""

from keras.layers.normalization import BatchNormalization

#ip_shape = (385,100,100,100)
#n_neurons = 200

#img_x = np.load('X.npy')
# img_y = np.load('Y.npy')
print(img_y.shape)
img_y=img_y[:(img_x.shape[0]*num_of_frames),:]
finalimg_x = np.reshape(finalimg_x,(img_x1.shape[0],num_of_frames,n_comp))

# img_y = np.reshape(img_y,(num_of_frames,finalimg_x.shape[1],6))
print(finalimg_x.shape,img_y.shape)



# *******************************************************
# creating Test Dataset for validation
test_img_x = []
test_img_y = []

print("Creating test frames....")
for i in  range(len(test)):
    vidObj = cv2.VideoCapture(test[i][0])
    label = test[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    test_img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        image = image/255
        # Saves the frames with frame-count 
        test_img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(test_img_y))

test_img_x = np.array(test_img_x)
test_img_y = np.array(test_img_y)
num = int(test_img_x.shape[0]/num_of_frames)
test_img_x = np.reshape(test_img_x,(num,num_of_frames,dim_x,dim_y))

img_x1= test_img_x[:test_img_x.shape[0],:]
img_x11=np.reshape(img_x1,(test_img_x.shape[0],num_of_frames,dim_x*dim_y))

test_finalimg_x=[]
#principalComponents = pca.fit_transform(img_x11)
for i in range(img_x11.shape[0]):
  principalComponents = pca.fit_transform(np.reshape(img_x11[i,:,:],(num_of_frames,dim_x*dim_y)))
  test_finalimg_x.append(principalComponents)
    
test_finalimg_x=np.array(test_finalimg_x)     
test_img_y=test_img_y[:(test_finalimg_x.shape[0]*num_of_frames),:] 
num = int(test_img_x.shape[0]/num_of_frames)
test_finalimg_x = np.reshape(test_finalimg_x,(test_finalimg_x.shape[0],num_of_frames,n_comp))

test_img_y = np.array(test_img_y)
# *********************************************************************************


model = Sequential()

model.add(LSTM(25,input_shape = (num_of_frames,n_comp),return_sequences = True,dropout = 0.4))
model.add(Flatten())
model.add(Dense(6,activation='softmax'))
#model.add(BatchNormalization())
model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])  
model.summary()

history = model.fit(finalimg_x, img_y, epochs=100,batch_size=64,validation_data=(test_finalimg_x, test_img_y))

import matplotlib.pyplot as plt
from matplotlib import style

plt.rcParams['figure.figsize'] = [10, 10]
style.use('fivethirtyeight')
# print(history.history)
loss = history.history['loss']
acc = history.history['acc']
val_acc = history.history['val_acc']
print(loss)
plt.plot(np.arange(100)+1,loss,linewidth='2')

plt.title('PCA+LSTM')
plt.xlabel('EPOCH')
plt.ylabel('LOSS')
plt.show()
print("\n\n")
print(acc)
plt.plot(np.arange(100)+1,acc,linewidth='2',label='TRAIN')
plt.plot(np.arange(100)+1,val_acc,linewidth='2',label='TEST')
plt.title('PCA+LSTM')
plt.xlabel('EPOCH')
plt.ylabel('ACCURACY')
plt.legend(loc='upper left')
plt.show()

"""Testing the above model on **TEST_SET**"""

test_img_x = []
test_img_y = []

print("Creating test frames....")
for i in  range(len(test)):
    vidObj = cv2.VideoCapture(test[i][0])
    label = test[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    test_img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        image = image/255
        # Saves the frames with frame-count 
        test_img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(test_img_y))

test_img_x = np.array(test_img_x)
test_img_y = np.array(test_img_y)
num = int(test_img_x.shape[0]/num_of_frames)
test_img_x = np.reshape(test_img_x,(num,num_of_frames,dim_x,dim_y))

img_x1= test_img_x[:test_img_x.shape[0],:]
img_x11=np.reshape(img_x1,(test_img_x.shape[0],num_of_frames,dim_x*dim_y))

finalimg_x=[]
#principalComponents = pca.fit_transform(img_x11)
for i in range(img_x11.shape[0]):
  principalComponents = pca.fit_transform(np.reshape(img_x11[i,:,:],(num_of_frames,dim_x*dim_y)))
  finalimg_x.append(principalComponents)
    
finalimg_x=np.array(finalimg_x)     
test_img_y=test_img_y[:(finalimg_x.shape[0]*num_of_frames),:] 
num = int(test_img_x.shape[0]/num_of_frames)
finalimg_x = np.reshape(finalimg_x,(finalimg_x.shape[0],num_of_frames,n_comp))

test_img_y = np.array(test_img_y)

print(finalimg_x.shape,test_img_y.shape)
print("Testing..")


acc = model.evaluate(finalimg_x,test_img_y)
print("Accuracy: ",100*acc[1])
