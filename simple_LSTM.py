# -*- coding: utf-8 -*-
"""simple_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0dX05PfFAllppVZ1OIlsJOJYV3QSPLM

Importing dataset from **GitHub** Directory
"""

!git clone https://github.com/pruvi007/ML_Datasets.git

"""From each directory getting videos for **Train and Test** purposes."""

import cv2
import os
import time
import sys
import argparse
import numpy as np 
import random

MAIN = "ML_Datasets/Videos/"
OP = "/media/diablo/Study Vids/VIDEOS_ENGINE/ML/python_ml_me/LSTM_project/Data"

# **********************************************************************************************
start = time.time()
print("Creating Dataset")

train_data = []
test_data = []
actions = ["boxing","handclapping","handwaving","jogging","walking"]

count = 0
level=0
for act in actions:
    folder = MAIN + act
    c = 0
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            c+=1
        
    test_percent = int(c/3)
    train_percent = c-test_percent

    flag = np.zeros(c+1)
    for x in range(test_percent):
        r = random.randint(0,c)
        flag[r]=1
    c=0
    
    for subdir,dirs,files in os.walk(folder):       
        for file in files:
            vid = folder+"/"+file
            s = vid.split("/")
            action_name = s[len(s)-2]
            if flag[c]==1:
                test_data.append([vid,action_name,level])
            else:
                train_data.append([vid,action_name,level])
            c+=1
    level+=1
print(len(train_data))
print(len(test_data))

# for i in range(len(train_data)):
#     print(train_data[i])
# print()
# for i in range(len(test_data)):
#     print(test_data[i])

np.random.shuffle(train_data)
np.random.shuffle(test_data)

train = []
test = []

for i in range(len(train_data)):
    train.append([train_data[i][0],train_data[i][2]])
for i in range(len(test_data)):
    test.append([test_data[i][0],test_data[i][2]])

# for i in range(len(train)):
#     print(train[i])
# print()
# for i in range(len(test)):
#     print(test[i])           

end = time.time()

print("Datsets Created. Done! Time: ",end - start)
# *************************************************************************************************

"""For each video** extracting frames** for both Train and Test sets"""

# ********************************************************************
# train the data 
import cv2
from keras.utils import to_categorical
from keras.models import Model,Sequential,load_model
from keras.layers import Dense,Conv3D,Dropout,Flatten,MaxPooling3D,Input
from keras.layers.recurrent import LSTM
import time 


img_x = []
img_y = []


start = time.time()
num_of_frames = 100
dim_x = 100
dim_y = 100
for i in  range(len(train)):
    vidObj = cv2.VideoCapture(train[i][0])
    label = train[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        # Saves the frames with frame-count 
        image = image/255
        img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(img_y))

img_x = np.array(img_x)
print(img_x.shape)
num = int(img_x.shape[0]/num_of_frames)
img_x = np.reshape(img_x,(num,num_of_frames,dim_x,dim_y))
print(img_x.shape)
img_y = np.array(img_y)
print(img_y.shape)

# np.save('X.npy',img_x)
# np.save('Y.npy',img_y)

"""creating the  model for** LSTM**

Training the Model and Obtaining the Train Accuracy.
"""

from keras.layers.normalization import BatchNormalization

# ip_shape = (392,200,100,100)
# n_neurons = 200

# img_x = np.load('X.npy')
# img_y = np.load('Y.npy')

img_x = np.reshape(img_x,(img_x.shape[0],num_of_frames,dim_x*dim_y))

# img_y = np.reshape(img_y,(num_of_frames,img_x.shape[1],6))
print(img_x.shape,img_y.shape)

# **********************************************
# create test sets

test_img_x = []
test_img_y = []

print("Creating test frames....")
for i in  range(len(test)):
    vidObj = cv2.VideoCapture(test[i][0])
    label = test[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    test_img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        # Saves the frames with frame-count 
        test_img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(test_img_y))

test_img_x = np.array(test_img_x)

num = int(test_img_x.shape[0]/num_of_frames)
test_img_x = np.reshape(test_img_x,(num,num_of_frames,dim_x,dim_y))

test_img_y = np.array(test_img_y)

test_img_x = np.reshape(test_img_x,(test_img_x.shape[0],num_of_frames,dim_x*dim_y))

# ***********************************************************
model = Sequential()

model.add(LSTM(50,input_shape = (num_of_frames,dim_x*dim_y),return_sequences =True,dropout = 0.2))
# model.add(LSTM(50,return_sequences=True,dropout=0.2))
model.add(Flatten())
model.add(Dense(6,activation='softmax'))
# model.add(BatchNormalization())
model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])  
model.summary()

history = model.fit(img_x, img_y, epochs=100,batch_size=124,validation_data=(test_img_x,test_img_y))
end = time.time()
print("\n\nTime to train the LSTM MODEL: ",end-start)

import matplotlib.pyplot as plt
from matplotlib import style

plt.rcParams['figure.figsize'] = [10, 10]
style.use('fivethirtyeight')
# print(history.history)
loss = history.history['loss']
acc = history.history['acc']
val_acc = history.history['val_acc']
print(loss)
plt.plot(np.arange(100)+1,loss,linewidth='2')

plt.title('LSTM')
plt.xlabel('EPOCH')
plt.ylabel('LOSS')
plt.show()
print("\n\n")
print(acc)
plt.plot(np.arange(100)+1,acc,linewidth='2',label='TRAIN')
plt.plot(np.arange(100)+1,val_acc,linewidth='2',label='TEST')
plt.title('LSTM')
plt.xlabel('EPOCH')
plt.ylabel('ACCURACY')
plt.legend(loc='upper left')
plt.show()

"""Testing the above model on** TEST SET.**"""

test_img_x = []
test_img_y = []

print("Creating test frames....")
for i in  range(len(test)):
    vidObj = cv2.VideoCapture(test[i][0])
    label = test[i][1]
#     print(label)
    Y_label= to_categorical(label, 6)
    test_img_y.append(Y_label)
    success = 1
    count=0
    while success: 
        
    #     print(Y_label)
        
#         vidObj.set(cv2.CAP_PROP_POS_MSEC,(count*200))	#0.2sec frames 
        success, image = vidObj.read()
        image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
        # Saves the frames with frame-count 
        test_img_x.append(cv2.resize(image,(dim_x,dim_y),interpolation = cv2.INTER_LINEAR))
        count += 1
        if count==num_of_frames:
            break
    
    
#     print(len(imgs))
    
#     model.fit(imgs, Y_label, epochs=5,batch_size=64)
print(len(test_img_y))

test_img_x = np.array(test_img_x)

num = int(test_img_x.shape[0]/num_of_frames)
test_img_x = np.reshape(test_img_x,(num,num_of_frames,dim_x,dim_y))

test_img_y = np.array(test_img_y)

test_img_x = np.reshape(test_img_x,(test_img_x.shape[0],num_of_frames,dim_x*dim_y))
# test_img_y = np.reshape(test_img_y,(num_of_frames,test_img_x.shape[1],6))
print(test_img_x.shape,test_img_y.shape)
print("Testing..")


acc = model.evaluate(test_img_x,test_img_y)
print("Accuracy: ",100*acc[1])
